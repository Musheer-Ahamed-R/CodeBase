Dynamic Programming  -
   -> Dynamic Programming is an algorithmic paradigm that solves a given complex problem by breaking it into subproblems and stores the results of subproblems to avoid
      computing the same results again. Following are the two main properties of a problem that suggest that the given problem can be solved using Dynamic programming.

      1) Overlapping Subproblems
      2) Optimal Substructure

      Overlapping Subproblems:
         -> Like Divide and Conquer, Dynamic Programming combines solutions to sub-problems. Dynamic Programming is mainly used when solutions of same subproblems
            are needed again and again. In dynamic programming, computed solutions to subproblems are stored in a table so that these don’t have to recomputed.
            So Dynamic Programming is not useful when there are no common (overlapping) subproblems because there is no point storing the solutions if they are not needed again.
            For example, Binary Search doesn’t have common subproblems. If we take example of following recursive program for Fibonacci Numbers, there are many subproblems
            which are solved again and again.

      Optimal Substructure:
         -> A given problems has Optimal Substructure Property if optimal solution of the given problem can be obtained by using optimal solutions of its subproblems.
            For example, the Shortest Path problem has following optimal substructure property:
            If a node x lies in the shortest path from a source node u to destination node v then the shortest path from u to v is combination of shortest path from u to x and shortest path from x to v.
            The standard All Pair Shortest Path algorithms like Floyd–Warshall and Bellman–Ford are typical examples of Dynamic Programming.
            On the other hand, the Longest Path problem doesn’t have the Optimal Substructure property. Here by Longest Path we mean longest simple path (path without cycle) between two nodes.


Tabulation vs Memoizatation

Tabulation Method(Bottom Up Dynamic Programming) : 

    -> As the name itself suggests starting from the bottom and cumulating answers to the top
    -> Iterative approach

Memoization Method(Top Down Dynamic Programming) : 

    -> Here, we start our journey from the top most destination state and compute its answer by taking in count the values of states that can
       reach the destination state, till we reach the bottom most base state.
    -> Here, we store and use the most recent cache up to a limit so that if next time we got a call for the same state we simply return it
       from the memory.
    -> Here, the memory may not be filled in a sequential manner.
    -> Recursive approach

Steps to solve a DP

    -> Identify if it is a DP problem
    -> Decide a state expression with 
       least parameters
    -> Formulate state relationship    
    -> Do tabulation (or add memoization)